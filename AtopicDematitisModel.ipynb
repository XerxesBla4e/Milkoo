{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "60c97b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os #helpful for manuplating files,directories\n",
    "import math #helpful for any mathematical computations\n",
    "import shutil #helpful for moving files from one directory to another\n",
    "import matplotlib\n",
    "import glob #works with image paths\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import load_model\n",
    "from keras.layers import GlobalAveragePooling2D, Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "923d7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of images 0-has atopic dematitis 1-doesn't have atopic dematitis\n",
    "ROOT_DIRECTORY = \"E:/datasets/brain_tumor_dataset\"\n",
    "num_of_images = {}\n",
    "\n",
    "for dir in os.listdir(ROOT_DIRECTORY):#directories with the root directory\n",
    "    num_of_images[dir] = len(os.listdir(os.path.join(ROOT_DIRECTORY, dir)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8984d705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('no', 17), ('yes', 17)])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_images.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96ca2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data such that\n",
    "#70% for Train Data\n",
    "#15% for validation\n",
    "#15% for testing\n",
    "\n",
    "#create train folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1cea0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateFolder(path, split):\n",
    "    if not os.path.exists(\"E:/datasets\"+path):\n",
    "        os.mkdir(\"E:/datasets/\"+path)\n",
    "        \n",
    "        for dir in os.listdir(ROOT_DIRECTORY):\n",
    "            os.makedirs(\"E:/datasets/\"+path+\"/\"+dir)\n",
    "            for img in np.random.choice(a = os.listdir(os.path.join(ROOT_DIRECTORY, dir)),\n",
    "                                    size = (math.floor(split*num_of_images[dir])-5),\n",
    "                                   replace=False ):\n",
    "                O = os.path.join(ROOT_DIRECTORY,dir,img)\n",
    "                D = os.path.join(\"E:/datasets/\",path,dir)\n",
    "                shutil.copy(O,D)\n",
    "                os.remove(O)\n",
    "    else:\n",
    "        print(f\"{path} Folder exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2c0260c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CreateFolder(\"train1\", 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c195ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CreateFolder(\"Val1\", 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ce8c51f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CreateFolder(\"test1\", 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254d0939",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "9396d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras underlying framework for tensorflow\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten,Dense, BatchNormalization, GlobalAvgPool2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "2f6c50e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_38 (Conv2D)          (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 111, 111, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 54, 54, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 52, 52, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 26, 26, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 12, 12, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 1, 1, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 1, 1, 64)          0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 171,329\n",
      "Trainable params: 171,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN model\n",
    "#kernel_size-size of convulational filter\n",
    "#activation_function-add up some non linearity\n",
    "#conv layer is basically the features of the image\n",
    "#add padding = 'same' to leave image size constant\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape = (224,224,3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(rate=0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(rate=0.25),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "bbbf4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary crossentropy since its a binary problem i.e, has or doesn't have\n",
    "loss_function = 'binary_crossentropy'\n",
    "model.compile(optimizer ='adam',loss=loss_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4626c",
   "metadata": {},
   "source": [
    "Data preparation and augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d6469a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingImage1(path):\n",
    "    \n",
    "    image_data = ImageDataGenerator(zoom_range= 0.2,\n",
    "                                   shear_range= 0.2,\n",
    "                                   rescale= 1/255,\n",
    "                                   horizontal_flip= True)\n",
    "    image = image_data.flow_from_directory(directory = path,\n",
    "                                          target_size = (224,224),\n",
    "                                          batch_size = 32,\n",
    "                                          class_mode = 'binary')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "8a2cb472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = \"E:/datasets/train1\"\n",
    "train_data = preprocessingImage1(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "31701449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingImage2(path):\n",
    "    \n",
    "    image_data = ImageDataGenerator(rescale= 1/255)\n",
    "    image = image_data.flow_from_directory(directory = path,\n",
    "                                          target_size = (224,224),\n",
    "                                          batch_size = 32,\n",
    "                                          class_mode = 'binary')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "65c5c30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 474 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = \"E:/datasets/test1\"\n",
    "test_data = preprocessingImage2(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "30dfdf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 474 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = \"E:/datasets/Val1\"\n",
    "val_data = preprocessingImage2(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "ed463903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "early stopping-incase results come early,\n",
    "avoids wasting resources due to \n",
    "further training of all other perimeters\n",
    "\"\"\"\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#hyperparameters\n",
    "#early stopping\n",
    "jamnyo = EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience= 3, verbose = 1, mode = 'auto')\n",
    "\n",
    "#model check point\n",
    "george = ModelCheckpoint(monitor=\"val_accuracy\", filepath=\"E:/datasets/atopicdema.h5\",verbose= 1, save_best_only=True , mode = 'auto')\n",
    "\n",
    "x = [jamnyo,george]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ea35ab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 863, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 532, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 668, in apply_gradients\n        grads_and_vars = self._aggregate_gradients(grads_and_vars)\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 484, in _aggregate_gradients\n        return self.gradient_aggregator(grads_and_vars)\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\utils.py\", line 33, in all_reduce_sum_gradients\n        if tf.__internal__.distribute.strategy_supports_no_merge_call():\n\n    AttributeError: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\XERXES~1\\AppData\\Local\\Temp/ipykernel_3576/2013990437.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 863, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 532, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 668, in apply_gradients\n        grads_and_vars = self._aggregate_gradients(grads_and_vars)\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 484, in _aggregate_gradients\n        return self.gradient_aggregator(grads_and_vars)\n    File \"C:\\Users\\XerxesCodes\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\utils.py\", line 33, in all_reduce_sum_gradients\n        if tf.__internal__.distribute.strategy_supports_no_merge_call():\n\n    AttributeError: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    batch_size=32,\n",
    "    validation_data=val_data,\n",
    "    verbose=1,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc591e",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492dbf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea35a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d9d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
